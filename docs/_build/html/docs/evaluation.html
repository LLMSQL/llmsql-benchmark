<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Evaluation API Reference &#8212; LLMSQL 0.1.15 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5349f25f" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=29da98fa" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=29da98fa" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/front_page.css?v=047bfc79" />
    <script src="../_static/documentation_options.js?v=e2f3408e"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/front_page.js?v=0a79e239"></script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Inference API Reference" href="inference.html" />
    <link rel="prev" title="Inference API Reference" href="inference.html" />
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="inference.html" title="Inference API Reference"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">LLMSQL 0.1.15 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">LLMSQL package Documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Evaluation API Reference</a></li>
        <li class="nav-item nav-item-this"><a href="">Evaluation API Reference</a></li>
      </ul>
    </div>
    </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">


  <section id="evaluation-api-reference">
<h1>Evaluation API Reference<a class="headerlink" href="#evaluation-api-reference" title="Link to this heading">¬∂</a></h1>
<p>The <cite>evaluate()</cite> function allows you to benchmark Text-to-SQL model outputs
against the LLMSQL gold queries and SQLite database. It prints metrics, logs
mismatches, and saves detailed reports automatically.</p>
<section id="features">
<h2>Features<a class="headerlink" href="#features" title="Link to this heading">¬∂</a></h2>
<ul class="simple">
<li><p>Evaluate model predictions from JSONL files or Python dicts.</p></li>
<li><p>Automatically download benchmark questions and SQLite DB if missing.</p></li>
<li><p>Prints mismatch summaries and supports configurable reporting.</p></li>
<li><p>Saves detailed JSON report with metrics, mismatches, timestamp, and input mode.</p></li>
</ul>
</section>
<section id="usage-examples">
<h2>Usage Examples<a class="headerlink" href="#usage-examples" title="Link to this heading">¬∂</a></h2>
<p>Evaluate from a JSONL file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">llmsql.evaluation.evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">evaluate</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="s2">&quot;path_to_outputs.jsonl&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
<p>Evaluate from a list of Python dicts:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;question_id&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted_sql&quot;</span><span class="p">:</span> <span class="s2">&quot;SELECT name FROM Table WHERE age &gt; 30&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;question_id&quot;</span><span class="p">:</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted_sql&quot;</span><span class="p">:</span> <span class="s2">&quot;SELECT COUNT(*) FROM Table&quot;</span><span class="p">},</span>
<span class="p">]</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
<p>Providing your own DB and questions (skip workdir):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">report</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
    <span class="s2">&quot;path_to_outputs.jsonl&quot;</span><span class="p">,</span>
    <span class="n">questions_path</span><span class="o">=</span><span class="s2">&quot;bench/questions.jsonl&quot;</span><span class="p">,</span>
    <span class="n">db_path</span><span class="o">=</span><span class="s2">&quot;bench/sqlite_tables.db&quot;</span><span class="p">,</span>
    <span class="n">workdir_path</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="function-arguments">
<h2>Function Arguments<a class="headerlink" href="#function-arguments" title="Link to this heading">¬∂</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 20.0%" />
<col style="width: 80.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>outputs</p></td>
<td><p>Path to JSONL file or a list of prediction dicts (required).</p></td>
</tr>
<tr class="row-odd"><td><p>workdir_path</p></td>
<td><p>Directory for automatic benchmark downloads. Ignored if both questions_path and db_path are provided. Default: ‚Äúllmsql_workdir‚Äù.</p></td>
</tr>
<tr class="row-even"><td><p>questions_path</p></td>
<td><p>Optional path to benchmark questions JSONL file.</p></td>
</tr>
<tr class="row-odd"><td><p>db_path</p></td>
<td><p>Optional path to SQLite DB with evaluation tables.</p></td>
</tr>
<tr class="row-even"><td><p>save_report</p></td>
<td><p>Path to save detailed JSON report. Defaults to ‚Äúevaluation_results_{uuid}.json‚Äù.</p></td>
</tr>
<tr class="row-odd"><td><p>show_mismatches</p></td>
<td><p>Print mismatches while evaluating. Default True.</p></td>
</tr>
<tr class="row-even"><td><p>max_mismatches</p></td>
<td><p>Maximum number of mismatches to display. Default 5.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="input-format">
<h2>Input Format<a class="headerlink" href="#input-format" title="Link to this heading">¬∂</a></h2>
<p>The predictions should be in JSONL format:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;question_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;predicted_sql&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SELECT name FROM Table WHERE age &gt; 30&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;question_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;predicted_sql&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SELECT COUNT(*) FROM Table&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;question_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;predicted_sql&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SELECT * FROM Table WHERE active=1&quot;</span><span class="p">}</span>
</pre></div>
</div>
</section>
<section id="output-metrics">
<h2>Output Metrics<a class="headerlink" href="#output-metrics" title="Link to this heading">¬∂</a></h2>
<p>The function returns a dictionary with the following keys:</p>
<ul class="simple">
<li><p>total ‚Äì Total queries evaluated</p></li>
<li><p>matches ‚Äì Queries where predicted SQL results match gold results</p></li>
<li><p>pred_none ‚Äì Queries where the model returned NULL or no result</p></li>
<li><p>gold_none ‚Äì Queries where the reference result was NULL or no result</p></li>
<li><p>sql_errors ‚Äì Invalid SQL or execution errors</p></li>
<li><p>accuracy ‚Äì Overall exact match accuracy</p></li>
<li><p>mismatches ‚Äì List of mismatched queries with details</p></li>
<li><p>timestamp ‚Äì Evaluation timestamp</p></li>
<li><p>input_mode ‚Äì How results were provided (‚Äújsonl_path‚Äù or ‚Äúdict_list‚Äù)</p></li>
</ul>
</section>
<section id="report-saving">
<h2>Report Saving<a class="headerlink" href="#report-saving" title="Link to this heading">¬∂</a></h2>
<p>By default, a report is saved automatically as <cite>evaluation_results_{uuid}.json</cite> in the current directory.
It contains metrics, mismatches, timestamp, and input mode. You can override this path using <cite>save_report</cite>.</p>
<p>‚Äî</p>
<p>‚Äî</p>
<div style="text-align:center; margin-top:2rem; color:#666;">
  üí¨ Made with ‚ù§Ô∏è by the LLMSQL Team
</div></section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Evaluation API Reference</a><ul>
<li><a class="reference internal" href="#features">Features</a></li>
<li><a class="reference internal" href="#usage-examples">Usage Examples</a></li>
<li><a class="reference internal" href="#function-arguments">Function Arguments</a></li>
<li><a class="reference internal" href="#input-format">Input Format</a></li>
<li><a class="reference internal" href="#output-metrics">Output Metrics</a></li>
<li><a class="reference internal" href="#report-saving">Report Saving</a></li>
<li><a class="reference internal" href="#report-saving">Report Saving</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="inference.html"
                          title="previous chapter">Inference API Reference</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/docs/evaluation.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="inference.html" title="Inference API Reference"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">LLMSQL 0.1.15 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >LLMSQL package Documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Evaluation API Reference</a></li>
        <li class="nav-item nav-item-this"><a href="">Evaluation API Reference</a></li>
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    </div>
  </body>
</html>
